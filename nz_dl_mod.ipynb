{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nz_dl_mod.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpZRdrq14qL/yb3cnszAJb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/widnu/Predictive_Policing_DL/blob/master/nz_dl_mod.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74owbDLPHimY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "751abaf3-e878-4b96-c85b-8a32c64d4c40"
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DLWazIzycWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "df=pd.read_csv('gdrive/My Drive/Colab Notebooks/dataset/nz_crime_dataset.csv', encoding='utf-8-sig')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmTYiXGH0Txt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "outputId": "62d87932-ca70-4cfc-e856-8c389c22b82f"
      },
      "source": [
        "df.info()\n",
        "df.describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1167347 entries, 0 to 1167346\n",
            "Data columns (total 19 columns):\n",
            " #   Column                     Non-Null Count    Dtype  \n",
            "---  ------                     --------------    -----  \n",
            " 0   DATE_NO_TIME               1167347 non-null  object \n",
            " 1   DATE_TIME                  1167347 non-null  object \n",
            " 2   DAY_AREA_CRIME_COUNT_ROLL  1167347 non-null  float64\n",
            " 3   DAY_AREA_CRIME_COUNT       1167347 non-null  int64  \n",
            " 4   MONTH_AREA_CRIME_COUNT     1167347 non-null  int64  \n",
            " 5   YEAR_AREA_CRIME_COUNT      1167347 non-null  int64  \n",
            " 6   TIME_SINCE_LAST_CRIME      1167347 non-null  float64\n",
            " 7   MONTH                      1167347 non-null  int64  \n",
            " 8   QUARTER                    1167347 non-null  float64\n",
            " 9   DAY_OF_WEEK                1167347 non-null  object \n",
            " 10  DAY                        1167347 non-null  float64\n",
            " 11  HOUR                       1167347 non-null  float64\n",
            " 12  HOUR_PARTITION             1167347 non-null  float64\n",
            " 13  MESHBLOCK                  1167347 non-null  int64  \n",
            " 14  AREA_0                     1167347 non-null  object \n",
            " 15  AREA_1                     1167347 non-null  object \n",
            " 16  WEAPON_TYPE                1167347 non-null  int64  \n",
            " 17  CRIME_TYPE                 1167347 non-null  object \n",
            " 18  RISK                       1167347 non-null  float64\n",
            "dtypes: float64(7), int64(6), object(6)\n",
            "memory usage: 169.2+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DAY_AREA_CRIME_COUNT_ROLL</th>\n",
              "      <th>DAY_AREA_CRIME_COUNT</th>\n",
              "      <th>MONTH_AREA_CRIME_COUNT</th>\n",
              "      <th>YEAR_AREA_CRIME_COUNT</th>\n",
              "      <th>TIME_SINCE_LAST_CRIME</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>QUARTER</th>\n",
              "      <th>DAY</th>\n",
              "      <th>HOUR</th>\n",
              "      <th>HOUR_PARTITION</th>\n",
              "      <th>MESHBLOCK</th>\n",
              "      <th>WEAPON_TYPE</th>\n",
              "      <th>RISK</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.167347e+06</td>\n",
              "      <td>1.167347e+06</td>\n",
              "      <td>1.167347e+06</td>\n",
              "      <td>1.167347e+06</td>\n",
              "      <td>1.167347e+06</td>\n",
              "      <td>1.167347e+06</td>\n",
              "      <td>1.167347e+06</td>\n",
              "      <td>1.167347e+06</td>\n",
              "      <td>1.167347e+06</td>\n",
              "      <td>1.167347e+06</td>\n",
              "      <td>1.167347e+06</td>\n",
              "      <td>1.167347e+06</td>\n",
              "      <td>1.167347e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.740339e+04</td>\n",
              "      <td>4.102593e+03</td>\n",
              "      <td>3.252062e+01</td>\n",
              "      <td>3.397887e+02</td>\n",
              "      <td>1.281016e-01</td>\n",
              "      <td>6.536036e+00</td>\n",
              "      <td>2.512512e+00</td>\n",
              "      <td>4.694526e+00</td>\n",
              "      <td>1.310084e+01</td>\n",
              "      <td>1.205440e+01</td>\n",
              "      <td>1.302863e+06</td>\n",
              "      <td>9.731468e-03</td>\n",
              "      <td>1.004760e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.485673e+03</td>\n",
              "      <td>2.827224e+03</td>\n",
              "      <td>3.752400e+01</td>\n",
              "      <td>4.161401e+02</td>\n",
              "      <td>7.455829e+00</td>\n",
              "      <td>3.552330e+00</td>\n",
              "      <td>1.149184e+00</td>\n",
              "      <td>1.891168e+00</td>\n",
              "      <td>4.183061e+00</td>\n",
              "      <td>4.167649e+00</td>\n",
              "      <td>8.577749e+05</td>\n",
              "      <td>1.042445e-01</td>\n",
              "      <td>7.758172e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.418400e+04</td>\n",
              "      <td>1.179000e+03</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.461000e+03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.655300e+04</td>\n",
              "      <td>1.628000e+03</td>\n",
              "      <td>1.000000e+01</td>\n",
              "      <td>9.300000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>1.262178e+01</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>6.075000e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.718400e+04</td>\n",
              "      <td>1.971000e+03</td>\n",
              "      <td>1.900000e+01</td>\n",
              "      <td>1.960000e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>1.317855e+01</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>1.167000e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.789000e+04</td>\n",
              "      <td>7.184000e+03</td>\n",
              "      <td>3.900000e+01</td>\n",
              "      <td>3.970000e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+01</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>1.400000e+01</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>2.029200e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.263600e+04</td>\n",
              "      <td>8.902000e+03</td>\n",
              "      <td>2.760000e+02</td>\n",
              "      <td>2.294000e+03</td>\n",
              "      <td>5.770000e+02</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>2.300000e+01</td>\n",
              "      <td>2.100000e+01</td>\n",
              "      <td>3.210003e+06</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       DAY_AREA_CRIME_COUNT_ROLL  ...          RISK\n",
              "count               1.167347e+06  ...  1.167347e+06\n",
              "mean                1.740339e+04  ...  1.004760e+00\n",
              "std                 1.485673e+03  ...  7.758172e-01\n",
              "min                 1.418400e+04  ...  0.000000e+00\n",
              "25%                 1.655300e+04  ...  0.000000e+00\n",
              "50%                 1.718400e+04  ...  1.000000e+00\n",
              "75%                 1.789000e+04  ...  2.000000e+00\n",
              "max                 2.263600e+04  ...  2.000000e+00\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FVtG3Ia1e09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "0674bbf2-1f0f-45e9-86b7-3e6d539b3b96"
      },
      "source": [
        "#######################################################\n",
        "# Count total NaN at each column in DataFrame\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Count all NaN in a DataFrame (both columns & Rows)\n",
        "print(df.isnull().sum().sum())\n",
        "\n",
        "# erase every row (axis=0) that has \"any\" Null value in it.\n",
        "df = df.dropna(how='any',axis=0) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DATE_NO_TIME                 0\n",
            "DATE_TIME                    0\n",
            "DAY_AREA_CRIME_COUNT_ROLL    0\n",
            "DAY_AREA_CRIME_COUNT         0\n",
            "MONTH_AREA_CRIME_COUNT       0\n",
            "YEAR_AREA_CRIME_COUNT        0\n",
            "TIME_SINCE_LAST_CRIME        0\n",
            "MONTH                        0\n",
            "QUARTER                      0\n",
            "DAY_OF_WEEK                  0\n",
            "DAY                          0\n",
            "HOUR                         0\n",
            "HOUR_PARTITION               0\n",
            "MESHBLOCK                    0\n",
            "AREA_0                       0\n",
            "AREA_1                       0\n",
            "WEAPON_TYPE                  0\n",
            "CRIME_TYPE                   0\n",
            "RISK                         0\n",
            "dtype: int64\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAzMTKyP1kOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######################################################\n",
        "feature_var = ['DAY_AREA_CRIME_COUNT_ROLL', 'MONTH', 'DAY', 'QUARTER', 'HOUR_PARTITION', 'AREA_0', 'AREA_1', 'WEAPON_TYPE', 'CRIME_TYPE']\n",
        "response_var = 'RISK'\n",
        "#######################################################\n",
        "X = df[feature_var]\n",
        "y = df.pop(response_var)\n",
        "# y = df[response_var]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWbzwzPw1sYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "58b2bca3-40dd-4556-f7de-f8a3953157d9"
      },
      "source": [
        "########################################\n",
        "# Encode categorical variables\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "oe = OrdinalEncoder()\n",
        "oe.fit(X)\n",
        "X = oe.transform(X)\n",
        "\n",
        "# from sklearn.decomposition import PCA\n",
        "# pca = PCA(n_components=5)\n",
        "# X = pca.fit_transform(X)\n",
        "\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# sc = StandardScaler()\n",
        "# X = sc.fit_transform(X)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le.fit(y)\n",
        "y = le.transform(y)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# from keras.utils import to_categorical\n",
        "# y = to_categorical(y)\n",
        "\n",
        "#######################################################\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "\n",
        "#######################################################\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 5)\n",
        "\n",
        "# Reserve 10,000 samples for validation\n",
        "X_val = X_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "X_train = X_train[:-10000]\n",
        "y_train = y_train[:-10000]\n",
        "\n",
        "#######################################################\n",
        "#df_X = pd.DataFrame(data=X)\n",
        "#df_y = pd.DataFrame(data=y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({1: 464704, 2: 354100, 0: 348543})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 464704, 1: 464704, 2: 464704})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNmYLYTX1yr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "#dataset = tf.data.Dataset.from_tensor_slices((df_X.values, df_y.values))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6GTytTP2Va0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_dataset = dataset.shuffle(len(df_X)).batch(1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMcBPgWI2OQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_compiled_model():\n",
        "    model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6P7I7Nx2mcT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a1f9fb9-13d7-4e32-faba-28b8274ed068"
      },
      "source": [
        "model = get_compiled_model()\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=128,\n",
        "    validation_data=(X_val, y_val),\n",
        ")\n",
        "\n",
        "history.history\n",
        "model.summary()\n",
        "\n",
        "# https://www.dlology.com/blog/how-to-choose-last-layer-activation-and-loss-function/\n",
        "\n",
        "##################################################\n",
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(X_test, y_test, batch_size=128)\n",
        "print(\"test loss, test acc:\", results)\n",
        "\n",
        "# Generate predictions (probabilities -- the output of the last layer)\n",
        "# on new data using `predict`\n",
        "print(\"Generate predictions for 3 samples\")\n",
        "predictions = model.predict(X_test[:3])\n",
        "print(\"predictions shape:\", predictions.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.9791 - accuracy: 0.5063 - val_loss: 0.9244 - val_accuracy: 0.5381\n",
            "Epoch 2/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.8894 - accuracy: 0.5683 - val_loss: 0.8594 - val_accuracy: 0.5858\n",
            "Epoch 3/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.8366 - accuracy: 0.6003 - val_loss: 0.8320 - val_accuracy: 0.6050\n",
            "Epoch 4/128\n",
            "15092/15092 [==============================] - 45s 3ms/step - loss: 0.8079 - accuracy: 0.6161 - val_loss: 0.7969 - val_accuracy: 0.6172\n",
            "Epoch 5/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.7887 - accuracy: 0.6270 - val_loss: 0.7914 - val_accuracy: 0.6252\n",
            "Epoch 6/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.7726 - accuracy: 0.6359 - val_loss: 0.7740 - val_accuracy: 0.6318\n",
            "Epoch 7/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.7604 - accuracy: 0.6424 - val_loss: 0.7486 - val_accuracy: 0.6537\n",
            "Epoch 8/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.7515 - accuracy: 0.6473 - val_loss: 0.7483 - val_accuracy: 0.6488\n",
            "Epoch 9/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.7444 - accuracy: 0.6513 - val_loss: 0.7424 - val_accuracy: 0.6508\n",
            "Epoch 10/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.7376 - accuracy: 0.6558 - val_loss: 0.7431 - val_accuracy: 0.6505\n",
            "Epoch 11/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.7341 - accuracy: 0.6576 - val_loss: 0.7387 - val_accuracy: 0.6533\n",
            "Epoch 12/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.7282 - accuracy: 0.6610 - val_loss: 0.7275 - val_accuracy: 0.6601\n",
            "Epoch 13/128\n",
            "15092/15092 [==============================] - 43s 3ms/step - loss: 0.7231 - accuracy: 0.6639 - val_loss: 0.7248 - val_accuracy: 0.6624\n",
            "Epoch 14/128\n",
            "15092/15092 [==============================] - 43s 3ms/step - loss: 0.7193 - accuracy: 0.6655 - val_loss: 0.7282 - val_accuracy: 0.6599\n",
            "Epoch 15/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.7152 - accuracy: 0.6680 - val_loss: 0.7214 - val_accuracy: 0.6695\n",
            "Epoch 16/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.7121 - accuracy: 0.6701 - val_loss: 0.7291 - val_accuracy: 0.6603\n",
            "Epoch 17/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.7077 - accuracy: 0.6721 - val_loss: 0.7262 - val_accuracy: 0.6585\n",
            "Epoch 18/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.7047 - accuracy: 0.6740 - val_loss: 0.6982 - val_accuracy: 0.6752\n",
            "Epoch 19/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.7014 - accuracy: 0.6760 - val_loss: 0.7040 - val_accuracy: 0.6798\n",
            "Epoch 20/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6986 - accuracy: 0.6775 - val_loss: 0.6972 - val_accuracy: 0.6742\n",
            "Epoch 21/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6963 - accuracy: 0.6791 - val_loss: 0.6992 - val_accuracy: 0.6771\n",
            "Epoch 22/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6939 - accuracy: 0.6798 - val_loss: 0.6900 - val_accuracy: 0.6777\n",
            "Epoch 23/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6920 - accuracy: 0.6814 - val_loss: 0.6865 - val_accuracy: 0.6835\n",
            "Epoch 24/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.6895 - accuracy: 0.6822 - val_loss: 0.7089 - val_accuracy: 0.6688\n",
            "Epoch 25/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6880 - accuracy: 0.6828 - val_loss: 0.6821 - val_accuracy: 0.6817\n",
            "Epoch 26/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6867 - accuracy: 0.6834 - val_loss: 0.6954 - val_accuracy: 0.6779\n",
            "Epoch 27/128\n",
            "15092/15092 [==============================] - 46s 3ms/step - loss: 0.6841 - accuracy: 0.6844 - val_loss: 0.6851 - val_accuracy: 0.6816\n",
            "Epoch 28/128\n",
            "15092/15092 [==============================] - 43s 3ms/step - loss: 0.6825 - accuracy: 0.6858 - val_loss: 0.7242 - val_accuracy: 0.6641\n",
            "Epoch 29/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6808 - accuracy: 0.6871 - val_loss: 0.6969 - val_accuracy: 0.6783\n",
            "Epoch 30/128\n",
            "15092/15092 [==============================] - 43s 3ms/step - loss: 0.6798 - accuracy: 0.6878 - val_loss: 0.6775 - val_accuracy: 0.6879\n",
            "Epoch 31/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6792 - accuracy: 0.6882 - val_loss: 0.6886 - val_accuracy: 0.6827\n",
            "Epoch 32/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6771 - accuracy: 0.6889 - val_loss: 0.6988 - val_accuracy: 0.6734\n",
            "Epoch 33/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6758 - accuracy: 0.6898 - val_loss: 0.6850 - val_accuracy: 0.6869\n",
            "Epoch 34/128\n",
            "15092/15092 [==============================] - 46s 3ms/step - loss: 0.6741 - accuracy: 0.6909 - val_loss: 0.6822 - val_accuracy: 0.6822\n",
            "Epoch 35/128\n",
            "15092/15092 [==============================] - 45s 3ms/step - loss: 0.6717 - accuracy: 0.6918 - val_loss: 0.6708 - val_accuracy: 0.6938\n",
            "Epoch 36/128\n",
            "15092/15092 [==============================] - 44s 3ms/step - loss: 0.6711 - accuracy: 0.6922 - val_loss: 0.6730 - val_accuracy: 0.6905\n",
            "Epoch 37/128\n",
            "15092/15092 [==============================] - 43s 3ms/step - loss: 0.6693 - accuracy: 0.6931 - val_loss: 0.7068 - val_accuracy: 0.6801\n",
            "Epoch 38/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6680 - accuracy: 0.6944 - val_loss: 0.6647 - val_accuracy: 0.6942\n",
            "Epoch 39/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.6673 - accuracy: 0.6948 - val_loss: 0.6660 - val_accuracy: 0.6931\n",
            "Epoch 40/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6657 - accuracy: 0.6953 - val_loss: 0.6641 - val_accuracy: 0.6954\n",
            "Epoch 41/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6651 - accuracy: 0.6956 - val_loss: 0.6676 - val_accuracy: 0.6913\n",
            "Epoch 42/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6627 - accuracy: 0.6966 - val_loss: 0.6642 - val_accuracy: 0.6999\n",
            "Epoch 43/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.6624 - accuracy: 0.6969 - val_loss: 0.6750 - val_accuracy: 0.6969\n",
            "Epoch 44/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6626 - accuracy: 0.6969 - val_loss: 0.6753 - val_accuracy: 0.6943\n",
            "Epoch 45/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6607 - accuracy: 0.6980 - val_loss: 0.6661 - val_accuracy: 0.6959\n",
            "Epoch 46/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6595 - accuracy: 0.6989 - val_loss: 0.6701 - val_accuracy: 0.6948\n",
            "Epoch 47/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6581 - accuracy: 0.6995 - val_loss: 0.6737 - val_accuracy: 0.6966\n",
            "Epoch 48/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6573 - accuracy: 0.6997 - val_loss: 0.6957 - val_accuracy: 0.6849\n",
            "Epoch 49/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6566 - accuracy: 0.7000 - val_loss: 0.6656 - val_accuracy: 0.6966\n",
            "Epoch 50/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6550 - accuracy: 0.7006 - val_loss: 0.6584 - val_accuracy: 0.6976\n",
            "Epoch 51/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6548 - accuracy: 0.7014 - val_loss: 0.6596 - val_accuracy: 0.7049\n",
            "Epoch 52/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6548 - accuracy: 0.7011 - val_loss: 0.6632 - val_accuracy: 0.6963\n",
            "Epoch 53/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6537 - accuracy: 0.7018 - val_loss: 0.6586 - val_accuracy: 0.6999\n",
            "Epoch 54/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6521 - accuracy: 0.7022 - val_loss: 0.6613 - val_accuracy: 0.6978\n",
            "Epoch 55/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6512 - accuracy: 0.7030 - val_loss: 0.6629 - val_accuracy: 0.6975\n",
            "Epoch 56/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6512 - accuracy: 0.7032 - val_loss: 0.6533 - val_accuracy: 0.7050\n",
            "Epoch 57/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6504 - accuracy: 0.7036 - val_loss: 0.6663 - val_accuracy: 0.7022\n",
            "Epoch 58/128\n",
            "15092/15092 [==============================] - 43s 3ms/step - loss: 0.6502 - accuracy: 0.7033 - val_loss: 0.6584 - val_accuracy: 0.7004\n",
            "Epoch 59/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6493 - accuracy: 0.7038 - val_loss: 0.6701 - val_accuracy: 0.6961\n",
            "Epoch 60/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.6483 - accuracy: 0.7046 - val_loss: 0.6557 - val_accuracy: 0.7023\n",
            "Epoch 61/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6475 - accuracy: 0.7053 - val_loss: 0.6476 - val_accuracy: 0.7070\n",
            "Epoch 62/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6470 - accuracy: 0.7051 - val_loss: 0.6565 - val_accuracy: 0.7035\n",
            "Epoch 63/128\n",
            "15092/15092 [==============================] - 38s 3ms/step - loss: 0.6464 - accuracy: 0.7059 - val_loss: 0.6801 - val_accuracy: 0.6888\n",
            "Epoch 64/128\n",
            "15092/15092 [==============================] - 38s 3ms/step - loss: 0.6460 - accuracy: 0.7056 - val_loss: 0.6501 - val_accuracy: 0.7017\n",
            "Epoch 65/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6447 - accuracy: 0.7065 - val_loss: 0.6602 - val_accuracy: 0.6979\n",
            "Epoch 66/128\n",
            "15092/15092 [==============================] - 44s 3ms/step - loss: 0.6450 - accuracy: 0.7061 - val_loss: 0.6816 - val_accuracy: 0.6882\n",
            "Epoch 67/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6457 - accuracy: 0.7060 - val_loss: 0.6604 - val_accuracy: 0.7018\n",
            "Epoch 68/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6439 - accuracy: 0.7071 - val_loss: 0.6492 - val_accuracy: 0.7111\n",
            "Epoch 69/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6428 - accuracy: 0.7073 - val_loss: 0.6487 - val_accuracy: 0.7045\n",
            "Epoch 70/128\n",
            "15092/15092 [==============================] - 38s 3ms/step - loss: 0.6422 - accuracy: 0.7076 - val_loss: 0.6453 - val_accuracy: 0.7019\n",
            "Epoch 71/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6417 - accuracy: 0.7081 - val_loss: 0.6608 - val_accuracy: 0.6970\n",
            "Epoch 72/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6414 - accuracy: 0.7083 - val_loss: 0.6530 - val_accuracy: 0.6983\n",
            "Epoch 73/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6398 - accuracy: 0.7090 - val_loss: 0.6429 - val_accuracy: 0.7065\n",
            "Epoch 74/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6399 - accuracy: 0.7085 - val_loss: 0.6532 - val_accuracy: 0.7042\n",
            "Epoch 75/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6391 - accuracy: 0.7091 - val_loss: 0.6539 - val_accuracy: 0.7054\n",
            "Epoch 76/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6385 - accuracy: 0.7094 - val_loss: 0.6801 - val_accuracy: 0.6938\n",
            "Epoch 77/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.6379 - accuracy: 0.7098 - val_loss: 0.6673 - val_accuracy: 0.6973\n",
            "Epoch 78/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6370 - accuracy: 0.7108 - val_loss: 0.6393 - val_accuracy: 0.7059\n",
            "Epoch 79/128\n",
            "15092/15092 [==============================] - 44s 3ms/step - loss: 0.6367 - accuracy: 0.7107 - val_loss: 0.6478 - val_accuracy: 0.7074\n",
            "Epoch 80/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6364 - accuracy: 0.7111 - val_loss: 0.6521 - val_accuracy: 0.7040\n",
            "Epoch 81/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6356 - accuracy: 0.7112 - val_loss: 0.6538 - val_accuracy: 0.7046\n",
            "Epoch 82/128\n",
            "15092/15092 [==============================] - 42s 3ms/step - loss: 0.6355 - accuracy: 0.7118 - val_loss: 0.6546 - val_accuracy: 0.7042\n",
            "Epoch 83/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6353 - accuracy: 0.7121 - val_loss: 0.6391 - val_accuracy: 0.7118\n",
            "Epoch 84/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6351 - accuracy: 0.7124 - val_loss: 0.6421 - val_accuracy: 0.7104\n",
            "Epoch 85/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6335 - accuracy: 0.7131 - val_loss: 0.6413 - val_accuracy: 0.7139\n",
            "Epoch 86/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6333 - accuracy: 0.7134 - val_loss: 0.6438 - val_accuracy: 0.7169\n",
            "Epoch 87/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6327 - accuracy: 0.7131 - val_loss: 0.6390 - val_accuracy: 0.7123\n",
            "Epoch 88/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6317 - accuracy: 0.7139 - val_loss: 0.6468 - val_accuracy: 0.7096\n",
            "Epoch 89/128\n",
            "15092/15092 [==============================] - 43s 3ms/step - loss: 0.6320 - accuracy: 0.7136 - val_loss: 0.6323 - val_accuracy: 0.7106\n",
            "Epoch 90/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.6307 - accuracy: 0.7147 - val_loss: 0.6379 - val_accuracy: 0.7121\n",
            "Epoch 91/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6297 - accuracy: 0.7149 - val_loss: 0.6356 - val_accuracy: 0.7162\n",
            "Epoch 92/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6295 - accuracy: 0.7148 - val_loss: 0.6447 - val_accuracy: 0.7099\n",
            "Epoch 93/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6290 - accuracy: 0.7151 - val_loss: 0.6471 - val_accuracy: 0.7076\n",
            "Epoch 94/128\n",
            "15092/15092 [==============================] - 44s 3ms/step - loss: 0.6297 - accuracy: 0.7150 - val_loss: 0.6316 - val_accuracy: 0.7154\n",
            "Epoch 95/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6281 - accuracy: 0.7161 - val_loss: 0.6435 - val_accuracy: 0.7094\n",
            "Epoch 96/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6279 - accuracy: 0.7158 - val_loss: 0.6430 - val_accuracy: 0.7074\n",
            "Epoch 97/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.6281 - accuracy: 0.7161 - val_loss: 0.6373 - val_accuracy: 0.7124\n",
            "Epoch 98/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6271 - accuracy: 0.7161 - val_loss: 0.6375 - val_accuracy: 0.7153\n",
            "Epoch 99/128\n",
            "15092/15092 [==============================] - 37s 2ms/step - loss: 0.6270 - accuracy: 0.7163 - val_loss: 0.6288 - val_accuracy: 0.7198\n",
            "Epoch 100/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6273 - accuracy: 0.7167 - val_loss: 0.6493 - val_accuracy: 0.7039\n",
            "Epoch 101/128\n",
            "15092/15092 [==============================] - 38s 2ms/step - loss: 0.6276 - accuracy: 0.7160 - val_loss: 0.6298 - val_accuracy: 0.7133\n",
            "Epoch 102/128\n",
            "15092/15092 [==============================] - 38s 3ms/step - loss: 0.6263 - accuracy: 0.7163 - val_loss: 0.6307 - val_accuracy: 0.7163\n",
            "Epoch 103/128\n",
            "15092/15092 [==============================] - 38s 3ms/step - loss: 0.6256 - accuracy: 0.7171 - val_loss: 0.6359 - val_accuracy: 0.7111\n",
            "Epoch 104/128\n",
            "15092/15092 [==============================] - 38s 3ms/step - loss: 0.6254 - accuracy: 0.7175 - val_loss: 0.6231 - val_accuracy: 0.7221\n",
            "Epoch 105/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6261 - accuracy: 0.7170 - val_loss: 0.6329 - val_accuracy: 0.7191\n",
            "Epoch 106/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6267 - accuracy: 0.7164 - val_loss: 0.6637 - val_accuracy: 0.7090\n",
            "Epoch 107/128\n",
            "15092/15092 [==============================] - 37s 2ms/step - loss: 0.6255 - accuracy: 0.7169 - val_loss: 0.6552 - val_accuracy: 0.7052\n",
            "Epoch 108/128\n",
            "15092/15092 [==============================] - 37s 2ms/step - loss: 0.6252 - accuracy: 0.7176 - val_loss: 0.6411 - val_accuracy: 0.7132\n",
            "Epoch 109/128\n",
            "15092/15092 [==============================] - 37s 2ms/step - loss: 0.6238 - accuracy: 0.7184 - val_loss: 0.6372 - val_accuracy: 0.7102\n",
            "Epoch 110/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6235 - accuracy: 0.7183 - val_loss: 0.6364 - val_accuracy: 0.7135\n",
            "Epoch 111/128\n",
            "15092/15092 [==============================] - 36s 2ms/step - loss: 0.6226 - accuracy: 0.7191 - val_loss: 0.6287 - val_accuracy: 0.7101\n",
            "Epoch 112/128\n",
            "15092/15092 [==============================] - 36s 2ms/step - loss: 0.6227 - accuracy: 0.7182 - val_loss: 0.6521 - val_accuracy: 0.7030\n",
            "Epoch 113/128\n",
            "15092/15092 [==============================] - 37s 2ms/step - loss: 0.6224 - accuracy: 0.7192 - val_loss: 0.6357 - val_accuracy: 0.7092\n",
            "Epoch 114/128\n",
            "15092/15092 [==============================] - 38s 3ms/step - loss: 0.6208 - accuracy: 0.7196 - val_loss: 0.6326 - val_accuracy: 0.7173\n",
            "Epoch 115/128\n",
            "15092/15092 [==============================] - 38s 3ms/step - loss: 0.6208 - accuracy: 0.7196 - val_loss: 0.6341 - val_accuracy: 0.7190\n",
            "Epoch 116/128\n",
            "15092/15092 [==============================] - 38s 2ms/step - loss: 0.6203 - accuracy: 0.7202 - val_loss: 0.6423 - val_accuracy: 0.7141\n",
            "Epoch 117/128\n",
            "15092/15092 [==============================] - 38s 2ms/step - loss: 0.6196 - accuracy: 0.7202 - val_loss: 0.6374 - val_accuracy: 0.7172\n",
            "Epoch 118/128\n",
            "15092/15092 [==============================] - 37s 2ms/step - loss: 0.6200 - accuracy: 0.7205 - val_loss: 0.6366 - val_accuracy: 0.7201\n",
            "Epoch 119/128\n",
            "15092/15092 [==============================] - 38s 3ms/step - loss: 0.6195 - accuracy: 0.7203 - val_loss: 0.6522 - val_accuracy: 0.7034\n",
            "Epoch 120/128\n",
            "15092/15092 [==============================] - 38s 3ms/step - loss: 0.6188 - accuracy: 0.7211 - val_loss: 0.6235 - val_accuracy: 0.7178\n",
            "Epoch 121/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6185 - accuracy: 0.7207 - val_loss: 0.6344 - val_accuracy: 0.7164\n",
            "Epoch 122/128\n",
            "15092/15092 [==============================] - 40s 3ms/step - loss: 0.6179 - accuracy: 0.7210 - val_loss: 0.6437 - val_accuracy: 0.7109\n",
            "Epoch 123/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6178 - accuracy: 0.7214 - val_loss: 0.6224 - val_accuracy: 0.7190\n",
            "Epoch 124/128\n",
            "15092/15092 [==============================] - 37s 2ms/step - loss: 0.6174 - accuracy: 0.7213 - val_loss: 0.6179 - val_accuracy: 0.7262\n",
            "Epoch 125/128\n",
            "15092/15092 [==============================] - 37s 2ms/step - loss: 0.6168 - accuracy: 0.7212 - val_loss: 0.6422 - val_accuracy: 0.7087\n",
            "Epoch 126/128\n",
            "15092/15092 [==============================] - 41s 3ms/step - loss: 0.6165 - accuracy: 0.7217 - val_loss: 0.6382 - val_accuracy: 0.7160\n",
            "Epoch 127/128\n",
            "15092/15092 [==============================] - 38s 3ms/step - loss: 0.6167 - accuracy: 0.7219 - val_loss: 0.6285 - val_accuracy: 0.7136\n",
            "Epoch 128/128\n",
            "15092/15092 [==============================] - 39s 3ms/step - loss: 0.6159 - accuracy: 0.7222 - val_loss: 0.6200 - val_accuracy: 0.7208\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  1280      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  16512     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  16512     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  16512     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  387       \n",
            "=================================================================\n",
            "Total params: 51,203\n",
            "Trainable params: 51,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Evaluate on test data\n",
            "3268/3268 [==============================] - 5s 1ms/step - loss: 0.6181 - accuracy: 0.7228\n",
            "test loss, test acc: [0.6181262135505676, 0.7228250503540039]\n",
            "Generate predictions for 3 samples\n",
            "predictions shape: (3, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}